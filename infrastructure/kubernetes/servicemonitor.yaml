# ServiceMonitor for Prometheus Operator
# Automatically discovers and scrapes metrics from services

---
# API Service Monitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: api-service-monitor
  namespace: aquaculture-prod
  labels:
    app: api-service
    prometheus: kube-prometheus
spec:
  # Select services to monitor
  selector:
    matchLabels:
      app: api-service
  
  # Namespace to monitor
  namespaceSelector:
    matchNames:
      - aquaculture-prod
  
  # Endpoint configuration
  endpoints:
    - port: http
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s
      
      # Relabeling for better metric organization
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: node
        - sourceLabels: [__meta_kubernetes_namespace]
          targetLabel: namespace

---
# ML Service Monitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: ml-service-monitor
  namespace: aquaculture-prod
  labels:
    app: ml-service
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: ml-service
  namespaceSelector:
    matchNames:
      - aquaculture-prod
  endpoints:
    - port: http
      path: /metrics
      interval: 30s
      scrapeTimeout: 10s
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_namespace]
          targetLabel: namespace

---
# PrometheusRule for Alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: aquaculture-alerts
  namespace: aquaculture-prod
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    - name: api-service-alerts
      interval: 30s
      rules:
        # High Error Rate Alert
        - alert: HighErrorRate
          expr: |
            rate(http_requests_total{status=~"5.."}[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
            service: api
          annotations:
            summary: "High error rate detected"
            description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.service }}"
        
        # High Latency Alert
        - alert: HighLatency
          expr: |
            histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
          for: 5m
          labels:
            severity: warning
            service: api
          annotations:
            summary: "High latency detected"
            description: "95th percentile latency is {{ $value }}s"
        
        # Pod Down Alert
        - alert: PodDown
          expr: |
            up{job="api-service"} == 0
          for: 2m
          labels:
            severity: critical
            service: api
          annotations:
            summary: "API service pod is down"
            description: "Pod {{ $labels.pod }} has been down for more than 2 minutes"
        
        # High Memory Usage
        - alert: HighMemoryUsage
          expr: |
            container_memory_usage_bytes{pod=~"api-service.*"} / 
            container_spec_memory_limit_bytes{pod=~"api-service.*"} > 0.9
          for: 5m
          labels:
            severity: warning
            service: api
          annotations:
            summary: "High memory usage"
            description: "Memory usage is {{ $value | humanizePercentage }}"
        
        # High CPU Usage
        - alert: HighCPUUsage
          expr: |
            rate(container_cpu_usage_seconds_total{pod=~"api-service.*"}[5m]) > 0.8
          for: 5m
          labels:
            severity: warning
            service: api
          annotations:
            summary: "High CPU usage"
            description: "CPU usage is {{ $value | humanizePercentage }}"
    
    - name: ml-service-alerts
      interval: 30s
      rules:
        # Model Inference Slow
        - alert: SlowInference
          expr: |
            histogram_quantile(0.95, rate(inference_duration_seconds_bucket[5m])) > 0.5
          for: 5m
          labels:
            severity: warning
            service: ml
          annotations:
            summary: "ML inference is slow"
            description: "95th percentile inference time is {{ $value }}s"
        
        # Model Not Loaded
        - alert: ModelNotLoaded
          expr: |
            model_loaded{} == 0
          for: 2m
          labels:
            severity: critical
            service: ml
          annotations:
            summary: "ML model not loaded"
            description: "Model {{ $labels.version }} is not loaded"
        
        # GPU Memory High
        - alert: HighGPUMemory
          expr: |
            gpu_memory_used_bytes / gpu_memory_total_bytes > 0.9
          for: 5m
          labels:
            severity: warning
            service: ml
          annotations:
            summary: "High GPU memory usage"
            description: "GPU memory usage is {{ $value | humanizePercentage }}"
